# -*- coding: utf-8 -*-
"""01_Classification.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m65HWgtha2fdXyztZ8857KF9CfY-_F7a
"""

# Tarea: Recrear esta misma metodología para un problema aún no visto

# Commented out IPython magic to ensure Python compatibility.
try:
#   %tensorflow_version 2.x # colab only
except Exception:
  pass

import tensorflow as tf
print(tf.__version__)

"""## Data pre processing"""

# load int the data
from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()
data

type(data)

data.keys()

data.data.shape # (m, d) m: número de muestras y d: número de features/características

data.target # Problema de clasificación binaria

data.target_names

data.target.shape # m debe ser igual que en data

data.data

# Es importante saber qué significan las features, por lo que debemos ver qué 
  # significa cada elemento

data.feature_names

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
                                                    data.data, data.target, 
                                                    test_size=0.33, random_state=31
                                                  )

M, D = X_train.shape

print(M, D)

# Debemos escalar la data

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train) # Ajustados (fit) solo en el entrenamiento,
                                          # dado que los parámetros del modelo deben ser ajustado a partir de este set de datos.
X_test = scaler.transform(X_test)



"""## Model building"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Input(shape=(D,)),
    tf.keras.layers.Dense(1, activation='sigmoid') # 1 porque solo queremos 1 output,
])

model.compile(
    optimizer='adam',
    loss='binary_crossentropy', # este loss va con el sigmoid y con la clasificación binaria
    metrics=['accuracy']
) #

"""## Model training"""

r = model.fit(X_train, y_train,
              validation_data=(X_test, y_test),
              epochs=100
              )

"""## Model results"""

print("Training score:", model.evaluate(X_train, y_train))
print("Test score:", model.evaluate(X_test, y_test))

import matplotlib.pyplot as plt
import seaborn as sns
sns.set_style('darkgrid')

# Ajusta el tamaño del gráfico (ancho, alto)
plt.figure(figsize=(12, 8))

# Grafica las curvas de pérdida y validación
plt.plot(r.history['loss'], label='loss')
plt.plot(r.history['val_loss'], label='validation_loss')

# Muestra la leyenda
plt.legend()

# Muestra el gráfico
plt.show()

# Ajusta el tamaño del gráfico (ancho, alto)
plt.figure(figsize=(12, 8))

plt.plot(r.history['accuracy'], label='accuracy')
plt.plot(r.history['val_accuracy'], label='validation_accuracy')

plt.legend();

plt.show()